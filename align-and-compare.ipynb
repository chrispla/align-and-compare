{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizing Hierarchical Structure for Audio-Based Music Similarity\n",
    "#### Christos Plachouras, ISMIR 2021 Late-Break Demo, [Code](https://github.com/chrispla/align-and-compare), [Paper](), [Poster](), [Video]()\n",
    "\n",
    "\n",
    "This notebook provides code for demonstrating how the method works for comparing two audio files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### > Library importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for audio processing\n",
    "import librosa\n",
    "# for plotting\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt \n",
    "# for matrix processing\n",
    "import numpy as np\n",
    "import scipy\n",
    "# for spectral clustering\n",
    "import sklearn.cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### > Loading audio\n",
    "Choose paths for the two audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "path1 = 'enter/path/here'\n",
    "path2 = 'enter/path/here'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### > Hierarchical structure analysis\n",
    "\n",
    "Code modified from [Brian McFee - Laplacian Segmentation (MIT License)](https://github.com/bmcfee/lsd_viz)\n",
    "\n",
    "Brian McFee, Dan Ellis. \"Analyzing Song Structure with Spectral Clustering\". ISMIR 2014.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant-Q Transform parameters\n",
    "BINS_PER_OCTAVE = 12 * 3\n",
    "N_OCTAVES = 7\n",
    "\n",
    "# Spectral clustering parameters (spectral clustering component translates to number of segment types)\n",
    "kmin = 2  # needs to be >=2\n",
    "kmax = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### >> Compute Laplacian\n",
    "First, we compute the Constant-Q Transform of the audio file and beat-synchronize it. Then, we compute an affinity matrix encoding the self-similarity of each frame of the CQT, and combine it with a sequence matrix encoding the local consistency of MFCCs. Finally, we compute the Laplacian to shift it to its matrix representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_laplacian(path, BINS_PER_OCTAVE, N_OCTAVES):\n",
    "    \"\"\"\n",
    "    Compute the Laplacian matrix from an audio file using\n",
    "    its Constant-Q Transform\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    path: filepath (str)\n",
    "\n",
    "    Output\n",
    "    -----\n",
    "    C: Constant-Q Transform (np.array)\n",
    "    L: Laplacian matrix (np.array)\n",
    "    \"\"\"\n",
    "\n",
    "    # load audio\n",
    "    y, sr = librosa.load(path, sr=22050, mono=True)\n",
    "\n",
    "    # Compute Constant-Q Transform in dB\n",
    "    C = librosa.amplitude_to_db(np.abs(librosa.cqt(y=y,\n",
    "                                                   sr=sr,\n",
    "                                                   bins_per_octave=BINS_PER_OCTAVE,\n",
    "                                                   n_bins=N_OCTAVES * BINS_PER_OCTAVE)),\n",
    "                                                   ref=np.max)\n",
    "\n",
    "    # beat tracking\n",
    "    tempo, beats = librosa.beat.beat_track(y=y, sr=sr, trim=False)\n",
    "    # get beat times in seconds\n",
    "    beat_times = librosa.frames_to_time(librosa.util.fix_frames(beats, x_min=0, x_max=C.shape[1]), sr=sr)\n",
    "\n",
    "    # beat synchronize the CQT\n",
    "    Csync = librosa.util.sync(C, beats, aggregate=np.median)\n",
    "\n",
    "    # stack 4 consecutive frames\n",
    "    Cstack = librosa.feature.stack_memory(Csync, 4)\n",
    "\n",
    "    # compute weighted recurrence matrix\n",
    "    R = librosa.segment.recurrence_matrix(Cstack, width=3, mode='affinity', sym=True)\n",
    "\n",
    "    # enhance diagonals with a median filter\n",
    "    df = librosa.segment.timelag_filter(scipy.ndimage.median_filter)\n",
    "    Rf = df(R, size=(1, 7))\n",
    "    Rf = librosa.segment.path_enhance(Rf, 15)\n",
    "\n",
    "    # compute MFCCs\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "    # beat synchronize them\n",
    "    Msync = librosa.util.sync(mfcc, beats)\n",
    "\n",
    "    # build the MFCC sequence matrix\n",
    "    path_distance = np.sum(np.diff(Msync, axis=1)**2, axis=0)\n",
    "    sigma = np.median(path_distance)\n",
    "    path_sim = np.exp(-path_distance / sigma)\n",
    "    R_path = np.diag(path_sim, k=1) + np.diag(path_sim, k=-1)\n",
    "\n",
    "    # get the balanced combination of the MFCC sequence matric and the CQT\n",
    "    deg_path = np.sum(R_path, axis=1)\n",
    "    deg_rec = np.sum(Rf, axis=1)\n",
    "    mu = deg_path.dot(deg_path + deg_rec) / np.sum((deg_path + deg_rec)**2)\n",
    "    A = mu * Rf + (1 - mu) * R_path\n",
    "\n",
    "    # compute the normalized Laplacian\n",
    "    L = scipy.sparse.csgraph.laplacian(A, normed=True)\n",
    "\n",
    "    return C, L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### >> Segment and cluster\n",
    "\n",
    "We eigendecompose the Laplacian and make sets of its first integer k in [kmin, kmax) eigenvectors. We then perform spectral clustering on each set using the respective number k of clusters. We also compute the Euclidean self-distance of the eigenvectors across time for each set to create \"approximations\" of the Laplacian for visualization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(L, kmin, kmax):\n",
    "    \"\"\"\n",
    "    Decompose Laplacian and make sets of its first integer k in [kmin, kmax] eigenvectors.\n",
    "    For each set, compute its Euclidean self distance over time, and do spectral clustering.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    L: Laplacian matrix (np.array)\n",
    "    kmin: first eigenvector index\n",
    "    kmax: last eigenvector index\n",
    "\n",
    "    Output\n",
    "    -----\n",
    "    distances: self distance matrix of each set of first eigenvectors (np.array, shape=(kmax-kmin, beats, beats))\n",
    "    segments: estimated structural segments for each set of first eigenvectors (np.array, shape=(kmax-kmin, beats))\n",
    "    \"\"\"\n",
    "\n",
    "    # eigendecomposition\n",
    "    evals, evecs = scipy.linalg.eigh(L)\n",
    "\n",
    "    # eigenvector filtering\n",
    "    evecs = scipy.ndimage.median_filter(evecs, size=(9, 1))\n",
    "\n",
    "    # normalization\n",
    "    Cnorm = np.cumsum(evecs**2, axis=1)**0.5\n",
    "\n",
    "    # initialize sets\n",
    "    distances = []\n",
    "    segments = []\n",
    "\n",
    "    for k in range(kmin, kmax):\n",
    "        # create set using first k normalized eigenvectors\n",
    "        Xs = evecs[:, :k] / Cnorm[:, k-1:k]\n",
    "\n",
    "        # get self distance over time of the set\n",
    "        distances.append(scipy.spatial.distance.squareform(scipy.spatial.distance.pdist(Xs, metric='euclidean')))\n",
    "\n",
    "        # cluster each set k using k clusters to get k segment types\n",
    "        KM = sklearn.cluster.KMeans(n_clusters=k, n_init=50, max_iter=500)\n",
    "        segments.append(KM.fit_predict(Xs))\n",
    "\n",
    "    return np.asarray(distances), np.asarray(segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### >> Run and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Laplacian using the Constant-Q Transform\n",
    "C1, L1 = compute_laplacian(path1, BINS_PER_OCTAVE, N_OCTAVES)\n",
    "C2, L2 = compute_laplacian(path2, BINS_PER_OCTAVE, N_OCTAVES)\n",
    "\n",
    "# Compute Laplacian approximations and hierarchical structural analysis \n",
    "d1, s1 = segment(L1, kmin, kmax)\n",
    "d2, s2 = segment(L2, kmin, kmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get relative scale of beat vectors for ploting\n",
    "cqt_scale1 = min(1, C1.shape[1]/C2.shape[1])\n",
    "cqt_scale2 = min(1, C2.shape[1]/C1.shape[1])\n",
    "seg_scale1 = min(1, s1.shape[1]/s2.shape[1])\n",
    "seg_scale2 = min(1, s2.shape[1]/s1.shape[1])\n",
    "\n",
    "# plot Constant-Q Transform\n",
    "for path, C, scale in zip([path1, path2], [C1, C2], [scale1, scale2]):\n",
    "    fig1, ax1 = plt.subplots(1, figsize=(15*scale, 5))\n",
    "    librosa.display.specshow(C, y_axis='cqt_hz', sr=22050,\n",
    "                                bins_per_octave=BINS_PER_OCTAVE,\n",
    "                                x_axis='s', ax=ax1)\n",
    "    ax1.set_title(path+\" - Constant-Q Transform\")\n",
    "\n",
    "# plot Laplacian approximations\n",
    "for path, d in zip([path1, path2], [d1, d2]):\n",
    "    fig2, ax2 = plt.subplots(1, kmax-kmin, figsize=(15, 3), sharey='all')\n",
    "    plt.set_cmap('viridis')\n",
    "    for k in range(kmax-kmin):\n",
    "        ax2[k].imshow(d[k], origin='lower', cmap='viridis', interpolation='none')\n",
    "        ax2[k].set_title(\"k = \" + str(kmin+k))\n",
    "    fig2.suptitle(path+\" - Approximations of Laplacian\")\n",
    "    ax2[0].set(xlabel='beats', ylabel='beats')\n",
    "\n",
    "# plot hierarchical structure\n",
    "y_ticks = np.arange(0, kmax-kmin)\n",
    "y_tick_labels = np.arange(kmin, kmax).astype(str)\n",
    "for path, s, scale in zip([path1, path2], [s1, s2], [seg_scale1, seg_scale2]):\n",
    "    fig3, ax3 = plt.subplots(1, 1, figsize=(15*scale, 10))\n",
    "    ax3.imshow(s, interpolation='none', aspect=20)\n",
    "    ax3.set_title(path+' - Hierarchical Structure')\n",
    "    ax3.set(xlabel='beats', ylabel='k')\n",
    "    ax3.set(yticks = y_ticks, yticklabels = y_tick_labels)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5fa8e7a0e7c7188de72acea4ae1bc222d1770499c4c3d36ce32843ef46b20053"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
